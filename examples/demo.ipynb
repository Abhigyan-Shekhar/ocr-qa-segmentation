{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# OCR & Question-Answer Segmentation Demo\n",
                "\n",
                "This notebook demonstrates the complete pipeline for processing handwritten exam images and extracting question-answer pairs using classical CV/ML techniques (no LLMs)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '../src')\n",
                "\n",
                "import numpy as np\n",
                "import cv2\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "\n",
                "from preprocessing import ImagePreprocessor\n",
                "from ocr_engine import OCREngine\n",
                "from feature_extraction import FeatureExtractor\n",
                "from crf_model import CRFModel\n",
                "from postprocessing import QAPairExtractor\n",
                "from utils import create_synthetic_training_data\n",
                "\n",
                "print(\"✓ All modules imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Train CRF Model (Synthetic Data)\n",
                "\n",
                "For demonstration purposes, we'll train a simple model on synthetic data. In production, you would use real annotated exam images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create synthetic training data\n",
                "print(\"Creating synthetic training data...\")\n",
                "X_train, y_train = create_synthetic_training_data(n_samples=50)\n",
                "\n",
                "print(f\"Training samples: {len(X_train)}\")\n",
                "print(f\"Features per sample: {len(X_train[0])}\")\n",
                "print(f\"\\nSample features (first line):\")\n",
                "for key, value in list(X_train[0][0].items())[:5]:\n",
                "    print(f\"  {key}: {value}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train CRF model\n",
                "print(\"Training CRF model...\")\n",
                "model = CRFModel(max_iterations=100)\n",
                "results = model.train(X_train, y_train)\n",
                "\n",
                "print(f\"\\n✓ Training complete!\")\n",
                "print(f\"Training F1: {results['train_f1']:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save model\n",
                "model_path = '../models/demo_crf_model.pkl'\n",
                "Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
                "model.save(model_path)\n",
                "print(f\"Model saved to: {model_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Process Sample Exam Image\n",
                "\n",
                "**Note:** For this demo to work with real images, you need to provide sample exam images in `examples/sample_data/`. For now, we'll demonstrate the pipeline components individually."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 Image Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment and modify this section if you have sample images\n",
                "\n",
                "# image_paths = [\n",
                "#     '../examples/sample_data/exam_page1.jpg',\n",
                "#     '../examples/sample_data/exam_page2.jpg'\n",
                "# ]\n",
                "\n",
                "# preprocessor = ImagePreprocessor(target_width=1200, enable_deskew=True)\n",
                "# processed, intermediate = preprocessor.process(image_paths, return_intermediate=True)\n",
                "\n",
                "# # Visualize preprocessing steps\n",
                "# fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "# axes[0].imshow(intermediate['resized'][0], cmap='gray')\n",
                "# axes[0].set_title('Original')\n",
                "# axes[0].axis('off')\n",
                "\n",
                "# axes[1].imshow(intermediate['deskewed'][0], cmap='gray')\n",
                "# axes[1].set_title('Deskewed')\n",
                "# axes[1].axis('off')\n",
                "\n",
                "# axes[2].imshow(processed, cmap='gray')\n",
                "# axes[2].set_title('Final (Stitched & Denoised)')\n",
                "# axes[2].axis('off')\n",
                "\n",
                "# plt.tight_layout()\n",
                "# plt.show()\n",
                "\n",
                "print(\"[DEMO] Skipping image preprocessing - no sample images provided\")\n",
                "print(\"To run with real images, add exam images to examples/sample_data/ and uncomment above code\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 OCR Extraction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment to run OCR on real images\n",
                "\n",
                "# ocr = OCREngine(engine='paddleocr', lang='en')\n",
                "# lines = ocr.extract_lines(processed)\n",
                "\n",
                "# print(f\"Extracted {len(lines)} text lines\\n\")\n",
                "# print(\"Sample lines:\")\n",
                "# for i, line in enumerate(lines[:5]):\n",
                "#     print(f\"  {i+1}. {line.text} (conf: {line.confidence:.2%})\")\n",
                "\n",
                "print(\"[DEMO] Skipping OCR - no sample images provided\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Feature Extraction Demo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demo feature extraction on synthetic line\n",
                "from ocr_engine import OCRLine\n",
                "\n",
                "# Create mock OCR lines\n",
                "mock_lines = [\n",
                "    OCRLine(text=\"Q1. What is machine learning?\", bbox=(50, 100, 400, 30), confidence=0.95, line_number=0),\n",
                "    OCRLine(text=\"Machine learning is a subset of AI\", bbox=(80, 150, 450, 25), confidence=0.88, line_number=1),\n",
                "    OCRLine(text=\"that enables systems to learn from data.\", bbox=(80, 180, 420, 25), confidence=0.90, line_number=2),\n",
                "]\n",
                "\n",
                "# Extract features\n",
                "feature_extractor = FeatureExtractor(image_width=800, image_height=1200)\n",
                "features = feature_extractor.extract_features(mock_lines)\n",
                "\n",
                "print(\"Features for first line:\")\n",
                "for key, value in features[0].items():\n",
                "    print(f\"  {key:25s}: {value}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.4 CRF Prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert features to CRF format and predict\n",
                "crf_features = feature_extractor.features_to_crf_format(features)\n",
                "tags = model.predict_single(crf_features)\n",
                "\n",
                "print(\"Predicted tags:\")\n",
                "for line, tag in zip(mock_lines, tags):\n",
                "    print(f\"  [{tag:5s}] {line.text}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.5 QA Pair Extraction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract QA pairs\n",
                "extractor = QAPairExtractor(min_confidence=0.3)\n",
                "pairs = extractor.extract_pairs(mock_lines, tags)\n",
                "\n",
                "# Display results\n",
                "print(extractor.pairs_to_formatted_text(pairs))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Feature Importance Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show top features for each label\n",
                "model.print_feature_weights(top_n=10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Complete End-to-End Pipeline Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_exam(image_paths, model_path):\n",
                "    \"\"\"\n",
                "    Complete pipeline for processing exam images.\n",
                "    \n",
                "    Args:\n",
                "        image_paths: List of image file paths\n",
                "        model_path: Path to trained CRF model\n",
                "        \n",
                "    Returns:\n",
                "        List of QA pairs\n",
                "    \"\"\"\n",
                "    # 1. Preprocessing\n",
                "    print(\"[1/5] Preprocessing...\")\n",
                "    preprocessor = ImagePreprocessor()\n",
                "    processed = preprocessor.process(image_paths)\n",
                "    \n",
                "    # 2. OCR\n",
                "    print(\"[2/5] Running OCR...\")\n",
                "    ocr = OCREngine(engine='paddleocr')\n",
                "    lines = ocr.extract_lines(processed)\n",
                "    print(f\"  Extracted {len(lines)} lines\")\n",
                "    \n",
                "    # 3. Feature extraction\n",
                "    print(\"[3/5] Extracting features...\")\n",
                "    img_width, img_height = ocr.get_image_dimensions(processed)\n",
                "    feature_extractor = FeatureExtractor(img_width, img_height)\n",
                "    features = feature_extractor.extract_features(lines)\n",
                "    crf_features = feature_extractor.features_to_crf_format(features)\n",
                "    \n",
                "    # 4. CRF prediction\n",
                "    print(\"[4/5] Running CRF model...\")\n",
                "    model = CRFModel()\n",
                "    model.load(model_path)\n",
                "    tags = model.predict_single(crf_features)\n",
                "    \n",
                "    # 5. Extract pairs\n",
                "    print(\"[5/5] Extracting QA pairs...\")\n",
                "    extractor = QAPairExtractor()\n",
                "    pairs = extractor.extract_pairs(lines, tags)\n",
                "    print(f\"  Extracted {len(pairs)} pairs\")\n",
                "    \n",
                "    return pairs\n",
                "\n",
                "print(\"✓ Pipeline function defined\")\n",
                "print(\"\\nTo use: pairs = process_exam(['exam1.jpg', 'exam2.jpg'], 'models/crf_model.pkl')\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "This notebook demonstrated:\n",
                "\n",
                "1. ✅ **CRF Model Training** on synthetic data\n",
                "2. ✅ **Feature Extraction** from OCR lines (visual + text features)\n",
                "3. ✅ **Sequence Labeling** using CRF\n",
                "4. ✅ **QA Pair Extraction** from tagged sequences\n",
                "5. ✅ **Feature Importance** analysis\n",
                "\n",
                "### Next Steps:\n",
                "\n",
                "- Add real exam images to `examples/sample_data/`\n",
                "- Annotate training data using `scripts/annotate.py`\n",
                "- Train production model with real data\n",
                "- Process full exam sets using `scripts/inference.py`\n",
                "\n",
                "**Remember:** This system uses classical CV/ML techniques (CRF, handcrafted features), **NOT Large Language Models**, ensuring interpretability and resource efficiency!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}