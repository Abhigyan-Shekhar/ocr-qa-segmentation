{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìù HTR using arshjot/Handwritten-Text-Recognition\n",
                "## Using the actual pre-trained CRNN model from the repo\n",
                "\n",
                "This notebook uses the **exact code** from [arshjot/Handwritten-Text-Recognition](https://github.com/arshjot/Handwritten-Text-Recognition) with their pre-trained model."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Install TensorFlow 1.15 (Required)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install TensorFlow 1.15 (last version before 2.x)\n",
                "!pip install tensorflow==1.15.0\n",
                "!pip install opencv-python-headless numpy matplotlib"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Clone the Repository"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!git clone https://github.com/arshjot/Handwritten-Text-Recognition.git\n",
                "%cd Handwritten-Text-Recognition"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Download Pre-trained Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download model from Google Drive\n",
                "!pip install gdown\n",
                "!gdown 1D97_MO_bOxfqxiJ8dtpbVX-xNzwQW0mY\n",
                "\n",
                "# Extract\n",
                "!tar -xzf CRNN_h128.tar.gz\n",
                "\n",
                "# Move to correct location\n",
                "!mkdir -p experiments\n",
                "!mv CRNN_h128 experiments/\n",
                "\n",
                "print(\"‚úÖ Model downloaded and extracted\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Upload Your Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "import os\n",
                "\n",
                "# Create samples directory\n",
                "!mkdir -p samples\n",
                "\n",
                "print(\"üì§ Upload your handwritten page image\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Move uploaded file to samples\n",
                "for filename in uploaded.keys():\n",
                "    !mv {filename} samples/\n",
                "    print(f\"‚úÖ Uploaded: {filename}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Segment Lines from Your Page\n",
                "\n",
                "The model works on **individual line images**, so we need to segment your full page first."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cv2\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from matplotlib.patches import Rectangle\n",
                "\n",
                "def segment_lines(image_path, output_dir='samples', min_line_height=20):\n",
                "    \"\"\"Segment page into lines\"\"\"\n",
                "    img = cv2.imread(image_path)\n",
                "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
                "    \n",
                "    # Denoise\n",
                "    denoised = cv2.fastNlMeansDenoising(gray, h=10)\n",
                "    \n",
                "    # Binarize\n",
                "    binary = cv2.adaptiveThreshold(\n",
                "        denoised, 255,\n",
                "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
                "        cv2.THRESH_BINARY_INV, 21, 10\n",
                "    )\n",
                "    \n",
                "    # Horizontal projection\n",
                "    h_projection = np.sum(binary, axis=1)\n",
                "    threshold = np.max(h_projection) * 0.1\n",
                "    \n",
                "    # Find line boundaries\n",
                "    in_line = False\n",
                "    line_start = 0\n",
                "    lines = []\n",
                "    \n",
                "    for i, val in enumerate(h_projection):\n",
                "        if not in_line and val > threshold:\n",
                "            line_start = i\n",
                "            in_line = True\n",
                "        elif in_line and val < threshold:\n",
                "            line_end = i\n",
                "            if line_end - line_start > min_line_height:\n",
                "                lines.append((line_start, line_end))\n",
                "            in_line = False\n",
                "    \n",
                "    if in_line:\n",
                "        lines.append((line_start, len(h_projection)))\n",
                "    \n",
                "    # Save line images\n",
                "    line_files = []\n",
                "    for idx, (y_start, y_end) in enumerate(lines):\n",
                "        # Add padding\n",
                "        y_start = max(0, y_start - 5)\n",
                "        y_end = min(gray.shape[0], y_end + 5)\n",
                "        \n",
                "        # Extract line\n",
                "        line_img = gray[y_start:y_end, :]\n",
                "        \n",
                "        # Find horizontal boundaries\n",
                "        v_projection = np.sum(binary[y_start:y_end, :], axis=0)\n",
                "        non_zero = np.where(v_projection > 0)[0]\n",
                "        \n",
                "        if len(non_zero) > 0:\n",
                "            x_start = max(0, non_zero[0] - 10)\n",
                "            x_end = min(gray.shape[1], non_zero[-1] + 10)\n",
                "            line_img = line_img[:, x_start:x_end]\n",
                "            \n",
                "            # Save\n",
                "            line_file = f'{output_dir}/line_{idx:02d}.png'\n",
                "            cv2.imwrite(line_file, line_img)\n",
                "            line_files.append(line_file)\n",
                "    \n",
                "    return line_files\n",
                "\n",
                "# Segment the uploaded image\n",
                "uploaded_file = list(uploaded.keys())[0]\n",
                "original_path = f'samples/{uploaded_file}'\n",
                "\n",
                "print(\"üîç Segmenting lines...\")\n",
                "line_files = segment_lines(original_path)\n",
                "print(f\"‚úÖ Created {len(line_files)} line images\")\n",
                "\n",
                "# Visualize\n",
                "for i, line_file in enumerate(line_files[:5]):\n",
                "    img = cv2.imread(line_file, cv2.IMREAD_GRAYSCALE)\n",
                "    plt.figure(figsize=(12, 2))\n",
                "    plt.imshow(img, cmap='gray')\n",
                "    plt.title(f'Line {i+1}')\n",
                "    plt.axis('off')\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Run Prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run the prediction script\n",
                "%cd mains\n",
                "!python predict.py -c ../configs/config.json"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7Ô∏è‚É£ View Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Results are printed above, but let's also save them\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"RECOGNITION COMPLETE\")\n",
                "print(\"=\"*80)\n",
                "print(\"\\nCheck the output above for recognized text from each line!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚ö†Ô∏è Troubleshooting\n",
                "\n",
                "If you get TensorFlow errors:\n",
                "1. **Restart runtime**: Runtime ‚Üí Restart runtime\n",
                "2. **Re-run from cell 1**\n",
                "\n",
                "If recognition is poor:\n",
                "- Ensure text is **black on white** background\n",
                "- Try adjusting image contrast/brightness\n",
                "- Check that lines are properly segmented (see visualizations above)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.0"
        },
        "colab": {
            "provenance": []
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}