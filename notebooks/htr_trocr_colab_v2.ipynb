{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ TrOCR Handwriting Recognition\n",
                "## Microsoft's Transformer-based OCR for Handwritten Text\n",
                "\n",
                "**Model**: [microsoft/trocr-base-handwritten](https://huggingface.co/microsoft/trocr-base-handwritten)\n",
                "\n",
                "**What it does:**\n",
                "- ‚úÖ State-of-the-art handwriting recognition\n",
                "- ‚úÖ Works on line images\n",
                "- ‚úÖ Easy to use (just pip install)\n",
                "- ‚úÖ No dependency hell"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q transformers pillow opencv-python-headless matplotlib torch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import cv2\n",
                "import matplotlib.pyplot as plt\n",
                "from matplotlib.patches import Rectangle\n",
                "from PIL import Image\n",
                "from google.colab import files\n",
                "\n",
                "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
                "\n",
                "print(\"‚úÖ Imports successful\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Load TrOCR Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üì• Loading TrOCR model...\")\n",
                "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')\n",
                "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')\n",
                "print(\"‚úÖ Model loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Upload Your Handwritten Page"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üì§ Upload your handwritten page\")\n",
                "uploaded_img = files.upload()\n",
                "\n",
                "if uploaded_img:\n",
                "    img_filename = list(uploaded_img.keys())[0]\n",
                "    print(f\"‚úÖ Uploaded: {img_filename}\")\n",
                "    \n",
                "    # Display\n",
                "    img = cv2.imread(img_filename)\n",
                "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "    plt.figure(figsize=(12, 8))\n",
                "    plt.imshow(img_rgb)\n",
                "    plt.axis('off')\n",
                "    plt.title('Original Image')\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Automatic Line Segmentation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def segment_lines(image_path, min_line_height=20):\n",
                "    \"\"\"\n",
                "    Segment handwritten page into text lines using horizontal projection\n",
                "    \"\"\"\n",
                "    # Read image\n",
                "    img = cv2.imread(image_path)\n",
                "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
                "    \n",
                "    # Denoise\n",
                "    denoised = cv2.fastNlMeansDenoising(gray, h=10)\n",
                "    \n",
                "    # Binarize\n",
                "    binary = cv2.adaptiveThreshold(\n",
                "        denoised, 255,\n",
                "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
                "        cv2.THRESH_BINARY_INV, 21, 10\n",
                "    )\n",
                "    \n",
                "    # Horizontal projection\n",
                "    h_projection = np.sum(binary, axis=1)\n",
                "    threshold = np.max(h_projection) * 0.1\n",
                "    \n",
                "    # Find line boundaries\n",
                "    in_line = False\n",
                "    line_start = 0\n",
                "    lines = []\n",
                "    \n",
                "    for i, val in enumerate(h_projection):\n",
                "        if not in_line and val > threshold:\n",
                "            line_start = i\n",
                "            in_line = True\n",
                "        elif in_line and val < threshold:\n",
                "            line_end = i\n",
                "            if line_end - line_start > min_line_height:\n",
                "                lines.append((line_start, line_end))\n",
                "            in_line = False\n",
                "    \n",
                "    if in_line:\n",
                "        lines.append((line_start, len(h_projection)))\n",
                "    \n",
                "    # Extract line images with PIL\n",
                "    line_images = []\n",
                "    bboxes = []\n",
                "    \n",
                "    for y_start, y_end in lines:\n",
                "        # Add padding\n",
                "        y_start = max(0, y_start - 5)\n",
                "        y_end = min(gray.shape[0], y_end + 5)\n",
                "        \n",
                "        # Extract line\n",
                "        line_img = gray[y_start:y_end, :]\n",
                "        \n",
                "        # Find horizontal boundaries\n",
                "        v_projection = np.sum(binary[y_start:y_end, :], axis=0)\n",
                "        non_zero = np.where(v_projection > 0)[0]\n",
                "        \n",
                "        if len(non_zero) > 0:\n",
                "            x_start = max(0, non_zero[0] - 10)\n",
                "            x_end = min(gray.shape[1], non_zero[-1] + 10)\n",
                "            line_img = line_img[:, x_start:x_end]\n",
                "            \n",
                "            # Convert to PIL Image (TrOCR expects PIL)\n",
                "            line_pil = Image.fromarray(line_img)\n",
                "            \n",
                "            line_images.append(line_pil)\n",
                "            bboxes.append((x_start, y_start, x_end - x_start, y_end - y_start))\n",
                "    \n",
                "    return line_images, bboxes\n",
                "\n",
                "print(\"‚úÖ Line segmentation function ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Segment lines\n",
                "if img_filename:\n",
                "    print(\"üîç Detecting text lines...\")\n",
                "    lines, line_bboxes = segment_lines(img_filename)\n",
                "    print(f\"‚úÖ Found {len(lines)} text lines\")\n",
                "    \n",
                "    # Visualize detected lines\n",
                "    img_display = cv2.imread(img_filename)\n",
                "    img_display = cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    fig, ax = plt.subplots(figsize=(14, 10))\n",
                "    ax.imshow(img_display)\n",
                "    \n",
                "    for i, (x, y, w, h) in enumerate(line_bboxes):\n",
                "        rect = Rectangle((x, y), w, h, linewidth=2, \n",
                "                        edgecolor='lime', facecolor='none')\n",
                "        ax.add_patch(rect)\n",
                "        ax.text(x, y-5, f'Line {i+1}', color='lime', \n",
                "               fontsize=12, fontweight='bold', \n",
                "               bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))\n",
                "    \n",
                "    ax.axis('off')\n",
                "    ax.set_title(f'Detected {len(lines)} Lines', fontsize=16, fontweight='bold')\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Run TrOCR on Each Line"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def recognize_line(line_image):\n",
                "    \"\"\"\n",
                "    Recognize text in a line image using TrOCR\n",
                "    \n",
                "    Args:\n",
                "        line_image: PIL Image of text line\n",
                "    Returns:\n",
                "        Recognized text string\n",
                "    \"\"\"\n",
                "    # Preprocess image\n",
                "    pixel_values = processor(line_image, return_tensors=\"pt\").pixel_values\n",
                "    \n",
                "    # Generate text\n",
                "    generated_ids = model.generate(pixel_values)\n",
                "    \n",
                "    # Decode\n",
                "    text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
                "    \n",
                "    return text\n",
                "\n",
                "print(\"‚úÖ Recognition function ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Process all lines\n",
                "if lines:\n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "    print(\"RECOGNITION RESULTS\")\n",
                "    print(\"=\"*80)\n",
                "    \n",
                "    full_text = []\n",
                "    \n",
                "    for i, line_img in enumerate(lines):\n",
                "        print(f\"\\nüîÑ Processing Line {i+1}...\", end=\" \")\n",
                "        \n",
                "        # Recognize\n",
                "        text = recognize_line(line_img)\n",
                "        full_text.append(text)\n",
                "        \n",
                "        print(f\"‚úÖ\")\n",
                "        \n",
                "        # Display line and prediction\n",
                "        fig, ax = plt.subplots(1, 1, figsize=(12, 2))\n",
                "        ax.imshow(line_img, cmap='gray')\n",
                "        ax.axis('off')\n",
                "        ax.set_title(f\"Line {i+1}: '{text}'\", fontsize=12, fontweight='bold')\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "        \n",
                "        print(f\"üìù Text: {text}\")\n",
                "        print(\"-\" * 80)\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "    print(\"FULL TEXT OUTPUT\")\n",
                "    print(\"=\"*80)\n",
                "    for i, line in enumerate(full_text, 1):\n",
                "        print(f\"{i}. {line}\")\n",
                "    print(\"=\"*80)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save to text file\n",
                "if 'full_text' in locals():\n",
                "    output_file = 'recognized_text.txt'\n",
                "    \n",
                "    with open(output_file, 'w') as f:\n",
                "        for i, line in enumerate(full_text, 1):\n",
                "            f.write(f\"{i}. {line}\\n\")\n",
                "    \n",
                "    print(f\"‚úÖ Results saved to {output_file}\")\n",
                "    \n",
                "    # Download\n",
                "    files.download(output_file)\n",
                "    print(\"‚úÖ File downloaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Summary\n",
                "\n",
                "**What this notebook does:**\n",
                "1. **Auto-segments** your handwritten page into text lines\n",
                "2. **Recognizes** each line using Microsoft's TrOCR\n",
                "3. **Outputs** the complete text\n",
                "\n",
                "**Why TrOCR?**\n",
                "- State-of-the-art accuracy on handwriting\n",
                "- Transformer-based (better than CNN+RNN)\n",
                "- Pre-trained on large handwriting datasets\n",
                "- Easy to use, no complex dependencies\n",
                "\n",
                "**For your internship assignment:**\n",
                "- ‚úÖ This handles **Task 1: OCR**\n",
                "- Next: Build **Task 2: Q&A Separation** (rule-based, no LLMs)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        },
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "accelerator": "GPU"
    },
    "nbformat": 4,
    "nbformat_minor": 4
}