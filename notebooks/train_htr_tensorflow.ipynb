{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üñäÔ∏è Handwritten Text Recognition (HTR) with CRNN + CTC\n",
                "## IAM Handwriting Dataset | TensorFlow/Keras\n",
                "\n",
                "---\n",
                "### üìã Setup\n",
                "1. **Add Data**: \"Add Data\" ‚Üí Search \"iam-handwriting-word-database\" ‚Üí Add\n",
                "2. **Enable GPU**: Settings ‚Üí Accelerator ‚Üí GPU\n",
                "3. **Run All!**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fix protobuf issue (MUST run before importing TensorFlow)\n",
                "import os\n",
                "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
                "print(\"‚úÖ Protobuf fix applied!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import cv2\n",
                "from pathlib import Path\n",
                "from typing import List, Tuple, Optional\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers, Model\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
                "\n",
                "print(f\"TensorFlow: {tf.__version__}\")\n",
                "print(f\"GPU: {len(tf.config.list_physical_devices('GPU')) > 0}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Explore Dataset Structure"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find the dataset\n",
                "DATA_ROOT = '/kaggle/input'\n",
                "\n",
                "print(\"üìÇ Available datasets:\")\n",
                "if os.path.exists(DATA_ROOT):\n",
                "    for item in os.listdir(DATA_ROOT):\n",
                "        print(f\"  üìÅ {item}\")\n",
                "else:\n",
                "    print(\"  (No input directory found)\")\n",
                "\n",
                "# Find the IAM dataset folder\n",
                "DATA_DIR = None\n",
                "if os.path.exists(DATA_ROOT):\n",
                "    for item in os.listdir(DATA_ROOT):\n",
                "        if 'iam' in item.lower() or 'handwriting' in item.lower():\n",
                "            DATA_DIR = os.path.join(DATA_ROOT, item)\n",
                "            break\n",
                "\n",
                "if DATA_DIR is None and os.path.exists(DATA_ROOT) and len(os.listdir(DATA_ROOT)) > 0:\n",
                "    DATA_DIR = os.path.join(DATA_ROOT, os.listdir(DATA_ROOT)[0])\n",
                "\n",
                "if DATA_DIR is None:\n",
                "    print(\"\\n‚ùå NO DATASET FOUND!\")\n",
                "    print(\"   Please add the dataset using the instructions above\")\n",
                "    print(\"   1. Click '+ Add Data' in the right sidebar\")\n",
                "    print(\"   2. Search 'iam-handwriting-word-database'\")\n",
                "    print(\"   3. Click 'Add'\")\n",
                "    DATA_DIR = DATA_ROOT  # Prevent crash\n",
                "else:\n",
                "    print(f\"\\nüìç Using: {DATA_DIR}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Explore dataset structure\n",
                "print(f\"\\nüìÇ Contents of {DATA_DIR}:\")\n",
                "\n",
                "def show_tree(path, prefix=\"\", max_depth=3, current_depth=0):\n",
                "    if current_depth >= max_depth:\n",
                "        return\n",
                "    try:\n",
                "        items = sorted(os.listdir(path))[:10]  # Show max 10 items\n",
                "        for item in items:\n",
                "            full_path = os.path.join(path, item)\n",
                "            if os.path.isdir(full_path):\n",
                "                print(f\"{prefix}üìÅ {item}/\")\n",
                "                show_tree(full_path, prefix + \"   \", max_depth, current_depth + 1)\n",
                "            else:\n",
                "                size = os.path.getsize(full_path) / 1024\n",
                "                print(f\"{prefix}üìÑ {item} ({size:.1f} KB)\")\n",
                "    except PermissionError:\n",
                "        pass\n",
                "    except FileNotFoundError:\n",
                "        print(f\"{prefix}(Directory not found)\")\n",
                "\n",
                "if DATA_DIR and os.path.exists(DATA_DIR):\n",
                "    show_tree(DATA_DIR)\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Skipping tree view (no dataset)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find words.txt and images directory\n",
                "print(\"üîç Searching for label files and image directories...\\n\")\n",
                "\n",
                "if DATA_DIR and os.path.exists(DATA_DIR):\n",
                "    # Find all .txt files\n",
                "    txt_files = list(Path(DATA_DIR).rglob('*.txt'))\n",
                "    print(f\"Found {len(txt_files)} .txt files:\")\n",
                "    for f in txt_files[:10]:\n",
                "        print(f\"  üìÑ {f}\")\n",
                "\n",
                "    # Find directories named 'words'\n",
                "    words_dirs = [d for d in Path(DATA_DIR).rglob('*') if d.is_dir() and 'word' in d.name.lower()]\n",
                "    print(f\"\\nFound {len(words_dirs)} word-related directories:\")\n",
                "    for d in words_dirs[:5]:\n",
                "        print(f\"  üìÅ {d}\")\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è Skipping file search (no dataset)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CONFIG = {\n",
                "    'img_height': 32,\n",
                "    'img_width': 128,\n",
                "    'batch_size': 64,\n",
                "    'epochs': 50,\n",
                "    'learning_rate': 0.001,\n",
                "    'val_split': 0.1,\n",
                "    'max_samples': None,  # Set to 10000 for quick test\n",
                "}\n",
                "\n",
                "# Character set\n",
                "CHARACTERS = list(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.,!?'-():;\\\"/ \")\n",
                "char_to_num = {char: idx + 1 for idx, char in enumerate(CHARACTERS)}\n",
                "num_to_char = {idx + 1: char for idx, char in enumerate(CHARACTERS)}\n",
                "num_to_char[0] = ''\n",
                "NUM_CLASSES = len(CHARACTERS) + 1\n",
                "\n",
                "print(f\"Character set: {NUM_CLASSES} classes\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def encode_label(text):\n",
                "    return [char_to_num.get(c, 0) for c in text if c in char_to_num]\n",
                "\n",
                "def decode_prediction(pred):\n",
                "    indices = np.argmax(pred, axis=1)\n",
                "    chars = []\n",
                "    prev_idx = -1\n",
                "    for idx in indices:\n",
                "        if idx != 0 and idx != prev_idx:\n",
                "            if idx in num_to_char:\n",
                "                chars.append(num_to_char[idx])\n",
                "        prev_idx = idx\n",
                "    return ''.join(chars)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_iam_dataset(data_dir, max_samples=None):\n",
                "    \"\"\"Load IAM dataset - handles various folder structures.\"\"\"\n",
                "    if not data_dir or not os.path.exists(data_dir):\n",
                "        raise FileNotFoundError(\"No dataset directory provided. Please add data first!\")\n",
                "\n",
                "    data_path = Path(data_dir)\n",
                "    samples = []\n",
                "    \n",
                "    # Find label file\n",
                "    words_file = None\n",
                "    for pattern in ['**/words*.txt', '**/labels*.txt', '**/*.txt']:\n",
                "        matches = list(data_path.glob(pattern))\n",
                "        for m in matches:\n",
                "            if m.stat().st_size > 10000:  # Must be reasonably large\n",
                "                words_file = m\n",
                "                break\n",
                "        if words_file:\n",
                "            break\n",
                "    \n",
                "    if not words_file:\n",
                "        raise FileNotFoundError(f\"No label file found in {data_dir}\")\n",
                "    \n",
                "    print(f\"üìÑ Using label file: {words_file}\")\n",
                "    \n",
                "    # Find images directory\n",
                "    images_dir = None\n",
                "    for d in data_path.rglob('*'):\n",
                "        if d.is_dir() and ('word' in d.name.lower() or 'image' in d.name.lower()):\n",
                "            # Check if it contains images\n",
                "            if list(d.rglob('*.png'))[:1]:\n",
                "                images_dir = d\n",
                "                break\n",
                "    \n",
                "    if not images_dir:\n",
                "        # Try to find any directory with PNG files\n",
                "        for d in data_path.rglob('*'):\n",
                "            if d.is_dir():\n",
                "                pngs = list(d.glob('*.png'))[:1]\n",
                "                if pngs:\n",
                "                    images_dir = d\n",
                "                    break\n",
                "    \n",
                "    print(f\"üìÅ Using images dir: {images_dir}\")\n",
                "    \n",
                "    # Parse label file\n",
                "    skipped = 0\n",
                "    with open(words_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
                "        for line in f:\n",
                "            if line.startswith('#') or line.strip() == '':\n",
                "                continue\n",
                "            \n",
                "            parts = line.strip().split(' ')\n",
                "            if len(parts) < 9:\n",
                "                continue\n",
                "            \n",
                "            word_id = parts[0]\n",
                "            status = parts[1]\n",
                "            transcription = parts[-1]\n",
                "            \n",
                "            if status == 'err':\n",
                "                continue\n",
                "            \n",
                "            # Filter out samples with zero-length encoded labels\n",
                "            encoded = encode_label(transcription)\n",
                "            if len(encoded) == 0:\n",
                "                skipped += 1\n",
                "                continue\n",
                "            \n",
                "            # Try to find the image\n",
                "            id_parts = word_id.split('-')\n",
                "            if len(id_parts) >= 3:\n",
                "                # Standard IAM structure\n",
                "                folder1 = id_parts[0]\n",
                "                folder2 = f\"{id_parts[0]}-{id_parts[1]}\"\n",
                "                \n",
                "                # Try various paths\n",
                "                possible_paths = [\n",
                "                    images_dir / folder1 / folder2 / f\"{word_id}.png\",\n",
                "                    images_dir / folder2 / f\"{word_id}.png\",\n",
                "                    images_dir / f\"{word_id}.png\",\n",
                "                ]\n",
                "                \n",
                "                for img_path in possible_paths:\n",
                "                    if img_path.exists():\n",
                "                        samples.append((str(img_path), transcription))\n",
                "                        break\n",
                "    \n",
                "    # If no samples found with standard parsing, try finding images directly\n",
                "    if len(samples) == 0:\n",
                "        print(\"‚ö†Ô∏è Standard parsing failed, trying direct image search...\")\n",
                "        all_pngs = list(data_path.rglob('*.png'))\n",
                "        print(f\"Found {len(all_pngs)} PNG files\")\n",
                "        \n",
                "        # For each image, try to find its label\n",
                "        with open(words_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
                "            label_dict = {}\n",
                "            for line in f:\n",
                "                if line.startswith('#') or line.strip() == '':\n",
                "                    continue\n",
                "                parts = line.strip().split(' ')\n",
                "                if len(parts) >= 9 and parts[1] != 'err':\n",
                "                    transcription = parts[-1]\n",
                "                    # Filter zero-length labels\n",
                "                    if len(encode_label(transcription)) > 0:\n",
                "                        label_dict[parts[0]] = transcription\n",
                "        \n",
                "        for img_path in all_pngs:\n",
                "            word_id = img_path.stem\n",
                "            if word_id in label_dict:\n",
                "                samples.append((str(img_path), label_dict[word_id]))\n",
                "    \n",
                "    if max_samples:\n",
                "        samples = samples[:max_samples]\n",
                "    \n",
                "    print(f\"‚úÖ Loaded {len(samples):,} samples (skipped {skipped:,} zero-length labels)\")\n",
                "    return samples"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load dataset\n",
                "print(\"üìÇ Loading IAM dataset...\")\n",
                "if DATA_DIR and os.path.exists(DATA_DIR):\n",
                "    all_samples = load_iam_dataset(DATA_DIR, max_samples=CONFIG['max_samples'])\n",
                "\n",
                "    # Shuffle and split\n",
                "    np.random.seed(42)\n",
                "    np.random.shuffle(all_samples)\n",
                "\n",
                "    n_val = int(len(all_samples) * CONFIG['val_split'])\n",
                "    train_samples = all_samples[n_val:]\n",
                "    val_samples = all_samples[:n_val]\n",
                "\n",
                "    print(f\"\\nüìä Train: {len(train_samples):,} | Val: {len(val_samples):,}\")\n",
                "else:\n",
                "    print(\"‚ùå No dataset to load. Please fix the error in Section 1.\")\n",
                "    train_samples = []\n",
                "    val_samples = []"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess_image(image_path, img_height=32, img_width=128):\n",
                "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
                "    if img is None:\n",
                "        return np.zeros((img_height, img_width, 1), dtype=np.float32)\n",
                "    \n",
                "    h, w = img.shape\n",
                "    new_width = min(int(w * (img_height / h)), img_width)\n",
                "    img = cv2.resize(img, (new_width, img_height))\n",
                "    \n",
                "    if new_width < img_width:\n",
                "        img = np.pad(img, ((0, 0), (0, img_width - new_width)), constant_values=255)\n",
                "    \n",
                "    img = 1.0 - (img.astype(np.float32) / 255.0)\n",
                "    return np.expand_dims(img, axis=-1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize samples\n",
                "if len(train_samples) > 0:\n",
                "    fig, axes = plt.subplots(2, 4, figsize=(14, 5))\n",
                "    for ax, (img_path, label) in zip(axes.flat, train_samples[:8]):\n",
                "        img = preprocess_image(img_path, CONFIG['img_height'], CONFIG['img_width'])\n",
                "        ax.imshow(img.squeeze(), cmap='gray')\n",
                "        ax.set_title(f'\"{label}\"', fontsize=10)\n",
                "        ax.axis('off')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è No samples to visualize\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Data Generator"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class IAMDataGenerator(keras.utils.Sequence):\n",
                "    def __init__(self, samples, img_height, img_width, batch_size, max_label_len=32, shuffle=True):\n",
                "        self.samples = samples\n",
                "        self.img_height = img_height\n",
                "        self.img_width = img_width\n",
                "        self.batch_size = batch_size\n",
                "        self.max_label_len = max_label_len\n",
                "        self.shuffle = shuffle\n",
                "        self.indices = np.arange(len(samples))\n",
                "        if shuffle:\n",
                "            np.random.shuffle(self.indices)\n",
                "    \n",
                "    def __len__(self):\n",
                "        if self.batch_size <= 0: return 0\n",
                "        return len(self.samples) // self.batch_size\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        batch_idx = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
                "        \n",
                "        images = np.zeros((self.batch_size, self.img_height, self.img_width, 1), dtype=np.float32)\n",
                "        labels = np.zeros((self.batch_size, self.max_label_len), dtype=np.int32)\n",
                "        # CTC input length: width / 2 based on pooling structure (64 time steps for 128 width)\n",
                "        input_lengths = np.full((self.batch_size, 1), self.img_width // 2, dtype=np.int32)\n",
                "        label_lengths = np.zeros((self.batch_size, 1), dtype=np.int32)\n",
                "        \n",
                "        for i, si in enumerate(batch_idx):\n",
                "            img_path, text = self.samples[si]\n",
                "            images[i] = preprocess_image(img_path, self.img_height, self.img_width)\n",
                "            encoded = encode_label(text)\n",
                "            label_len = min(len(encoded), self.max_label_len)\n",
                "            labels[i, :label_len] = encoded[:label_len]\n",
                "            label_lengths[i] = label_len\n",
                "        \n",
                "        return {'image': images, 'label': labels, 'input_length': input_lengths, 'label_length': label_lengths}, np.zeros(self.batch_size)\n",
                "    \n",
                "    def on_epoch_end(self):\n",
                "        if self.shuffle:\n",
                "            np.random.shuffle(self.indices)\n",
                "\n",
                "if len(train_samples) > 0:\n",
                "    train_gen = IAMDataGenerator(train_samples, CONFIG['img_height'], CONFIG['img_width'], CONFIG['batch_size'])\n",
                "    val_gen = IAMDataGenerator(val_samples, CONFIG['img_height'], CONFIG['img_width'], CONFIG['batch_size'], shuffle=False)\n",
                "    print(f\"‚úÖ Generators ready: {len(train_gen)} train batches, {len(val_gen)} val batches\")\n",
                "else:\n",
                "    train_gen = None\n",
                "    val_gen = None\n",
                "    print(\"‚ö†Ô∏è Generators not created (no data)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ CRNN Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_model(img_height, img_width, num_classes):\n",
                "    input_img = layers.Input(shape=(img_height, img_width, 1), name='image')\n",
                "    labels = layers.Input(shape=(None,), dtype='int32', name='label')\n",
                "    input_length = layers.Input(shape=(1,), dtype='int32', name='input_length')\n",
                "    label_length = layers.Input(shape=(1,), dtype='int32', name='label_length')\n",
                "    \n",
                "    # CNN\n",
                "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(input_img)\n",
                "    x = layers.MaxPooling2D((2, 2))(x)\n",
                "    \n",
                "    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
                "    x = layers.MaxPooling2D((2, 1))(x)  # Keep more width (64)\n",
                "    \n",
                "    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
                "    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n",
                "    x = layers.MaxPooling2D((2, 1))(x)\n",
                "    \n",
                "    x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "    x = layers.Conv2D(512, 3, activation='relu', padding='same')(x)\n",
                "    x = layers.BatchNormalization()(x)\n",
                "    x = layers.MaxPooling2D((2, 1))(x)\n",
                "    \n",
                "    # Last conv reduces height from 2 to 1, keeps width at 64\n",
                "    x = layers.Conv2D(512, (2, 1), activation='relu', padding='valid')(x)\n",
                "    \n",
                "    # Reshape: (Batch, 1, 64, 512) -> (Batch, 64, 512)\n",
                "    target_shape = (x.shape[2], x.shape[3])\n",
                "    x = layers.Reshape(target_shape)(x)\n",
                "    \n",
                "    x = layers.Dense(256, activation='relu')(x)\n",
                "    x = layers.Dropout(0.25)(x)\n",
                "    \n",
                "    # BiLSTM\n",
                "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=0.2))(x)\n",
                "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True, dropout=0.2))(x)\n",
                "    x = layers.Dense(num_classes, activation='softmax', name='output')(x)\n",
                "    \n",
                "    # CTC\n",
                "    ctc = layers.Lambda(lambda args: keras.backend.ctc_batch_cost(*args))([labels, x, input_length, label_length])\n",
                "    \n",
                "    train_model = Model([input_img, labels, input_length, label_length], ctc)\n",
                "    pred_model = Model(input_img, x)\n",
                "    return train_model, pred_model\n",
                "\n",
                "training_model, prediction_model = build_model(CONFIG['img_height'], CONFIG['img_width'], NUM_CLASSES)\n",
                "training_model.compile(optimizer=keras.optimizers.Adam(CONFIG['learning_rate']), loss=lambda y, p: p)\n",
                "print(f\"‚úÖ Model: {training_model.count_params():,} params\")\n",
                "training_model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7Ô∏è‚É£ Train!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if train_gen and len(train_gen) > 0:\n",
                "    callbacks = [\n",
                "        ModelCheckpoint('best_model.weights.h5', save_best_only=True, save_weights_only=True),\n",
                "        ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-6),\n",
                "        EarlyStopping(patience=10, restore_best_weights=True)\n",
                "    ]\n",
                "\n",
                "    print(\"üöÄ Starting training...\")\n",
                "    history = training_model.fit(train_gen, validation_data=val_gen, epochs=CONFIG['epochs'], callbacks=callbacks)\n",
                "else:\n",
                "    print(\"‚ùå Skipping training (no data).\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot\n",
                "if 'history' in locals():\n",
                "    plt.plot(history.history['loss'], label='Train')\n",
                "    plt.plot(history.history['val_loss'], label='Val')\n",
                "    plt.legend()\n",
                "    plt.title('Loss')\n",
                "    plt.savefig('loss.png')\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"No history to plot\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8Ô∏è‚É£ Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict(image_path):\n",
                "    img = preprocess_image(image_path, CONFIG['img_height'], CONFIG['img_width'])\n",
                "    pred = prediction_model.predict(np.expand_dims(img, 0), verbose=0)\n",
                "    return decode_prediction(pred[0])\n",
                "\n",
                "# Test\n",
                "if len(val_samples) > 0:\n",
                "    fig, axes = plt.subplots(3, 4, figsize=(14, 8))\n",
                "    for ax, (path, label) in zip(axes.flat, val_samples[:12]):\n",
                "        pred = predict(path)\n",
                "        ax.imshow(preprocess_image(path).squeeze(), cmap='gray')\n",
                "        ax.set_title(f'P:\"{pred}\"\\nL:\"{label}\"', fontsize=9, color='green' if pred==label else 'red')\n",
                "        ax.axis('off')\n",
                "    plt.tight_layout()\n",
                "    plt.savefig('predictions.png')\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"No validation samples to test\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save models and outputs\n",
                "import shutil\n",
                "\n",
                "print(\"üíæ Saving outputs...\")\n",
                "prediction_model.save('htr_model.keras')\n",
                "\n",
                "# Copy to /kaggle/working/ if not already there\n",
                "output_dir = '/kaggle/working'\n",
                "current_dir = os.getcwd()\n",
                "\n",
                "for filename in ['htr_model.keras', 'best_model.weights.h5', 'loss.png', 'predictions.png']:\n",
                "    if os.path.exists(filename):\n",
                "        src = os.path.abspath(filename)\n",
                "        dst = os.path.join(output_dir, filename)\n",
                "        \n",
                "        # Only copy if source and destination are different\n",
                "        if os.path.abspath(src) != os.path.abspath(dst):\n",
                "            shutil.copy(src, dst)\n",
                "            print(f\"  ‚úÖ Copied {filename}\")\n",
                "        else:\n",
                "            print(f\"  ‚úÖ {filename} (already in output dir)\")\n",
                "    else:\n",
                "        print(f\"  ‚ö†Ô∏è {filename} not found\")\n",
                "\n",
                "print(f\"\\n‚úÖ All outputs saved to {output_dir}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        },
        "kaggle": {
            "accelerator": "gpu",
            "isGpuEnabled": true,
            "isInternetEnabled": true
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}